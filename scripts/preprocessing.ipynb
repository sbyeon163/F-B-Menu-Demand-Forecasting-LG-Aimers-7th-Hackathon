{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ac27b95",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "id": "4c38ed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "from matplotlib import rc\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299c2b49",
   "metadata": {},
   "source": [
    "# Read csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "id": "b26e1227",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../../data/sample_submission.csv')\n",
    "holidays = pd.read_csv('../../data/holidays_2023_2025.csv')\n",
    "train = pd.read_csv('../../data/train/train.csv')\n",
    "# os.getcwd()\n",
    "terms = pd.read_csv('../solar_term_2023_2025.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa6c8f1",
   "metadata": {},
   "source": [
    "# Feature about date\n",
    "1. year\n",
    "2. month\n",
    "3. day\n",
    "4. weekday\n",
    "5. is_holiday\n",
    "6. is_sandwich\n",
    "7. is_before_holiday\n",
    "8. is_after_holiday\n",
    "9. is_weekend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "id": "780e82a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜 범위\n",
    "dates = pd.date_range(start=\"2023-01-01\", end=\"2025-05-31\", freq=\"D\")\n",
    "\n",
    "# 연, 월, 일 col 생성\n",
    "train['영업일자'] = pd.to_datetime(train['영업일자'])\n",
    "train['year'] = train['영업일자'].dt.year\n",
    "train['month'] = train['영업일자'].dt.month\n",
    "train['day'] = train['영업일자'].dt.day\n",
    "# 영업장, 메뉴명 col 생성\n",
    "train[['영업장명', '메뉴명']] = train['영업장명_메뉴명'].str.split('_', expand=True)\n",
    "# 요일 col 생성\n",
    "train['weekday'] = train['영업일자'].dt.weekday.astype(int)\n",
    "\n",
    "# 공휴일 col 생성\n",
    "holidays[\"locdate\"] = pd.to_datetime(holidays[\"locdate\"])\n",
    "holiday_dates = set(holidays['locdate'])\n",
    "train['is_holiday'] = train['영업일자'].isin(holiday_dates).astype(int)\n",
    "\n",
    "train['is_weekend'] = train['weekday'].apply(lambda x: 1 if x in [5, 6] else 0)\n",
    "\n",
    "# is_sandwich: 오늘은 평일(0)이고, 어제/내일이 모두 쉬는 날(1)인 경우 1\n",
    "train[\"non_work\"] = ((train[\"is_holiday\"] == 1) | (train[\"is_weekend\"] == 1)).astype(int)\n",
    "\n",
    "train[\"is_sandwich\"] = 0\n",
    "train.loc[\n",
    "    (train[\"non_work\"] == 0) &\n",
    "    (train[\"non_work\"].shift(1) == 1) &\n",
    "    (train[\"non_work\"].shift(-1) == 1),\n",
    "    \"is_sandwich\"\n",
    "] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c58fd0",
   "metadata": {},
   "source": [
    "# weekday_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "id": "cc306583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요일 컬럼 만들기\n",
    "train['weekday'] = pd.to_datetime(train['영업일자']).dt.weekday  # 0=월, 6=일\n",
    "\n",
    "# 메뉴별 요일별 평균 매출 계산\n",
    "menu_dow_avg = (\n",
    "    train.groupby(['영업장명_메뉴명','weekday'], as_index=False)['매출수량']\n",
    "         .mean()\n",
    "         .rename(columns={'매출수량':'요일평균매출'})\n",
    ")\n",
    "\n",
    "# 메뉴별 min–max 스케일링 (요일 단위)\n",
    "g = menu_dow_avg.groupby('영업장명_메뉴명')['요일평균매출']\n",
    "menu_dow_avg['weekday_score'] = (menu_dow_avg['요일평균매출'] - g.transform('min')) / \\\n",
    "                             (g.transform('max') - g.transform('min'))\n",
    "\n",
    "# max=min → 모든 요일 평균이 동일 → 1로 통일\n",
    "menu_dow_avg.loc[g.transform('max') == g.transform('min'), 'weekday_score'] = 1.0\n",
    "\n",
    "# 원본 데이터에 merge\n",
    "train = train.merge(\n",
    "    menu_dow_avg[['영업장명_메뉴명','weekday','weekday_score']],\n",
    "    on=['영업장명_메뉴명','weekday'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065c7101",
   "metadata": {},
   "source": [
    "# month_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "id": "dc3b9ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 메뉴별 월별 평균 매출 계산\n",
    "menu_month_avg = (\n",
    "    train.groupby(['영업장명_메뉴명','month'], as_index=False)['매출수량']\n",
    "         .mean()\n",
    "         .rename(columns={'매출수량':'월별평균매출'})\n",
    ")\n",
    "\n",
    "# 메뉴별 min–max 스케일링 (월 단위)\n",
    "g = menu_month_avg.groupby('영업장명_메뉴명')['월별평균매출']\n",
    "menu_month_avg['month_score'] = (menu_month_avg['월별평균매출'] - g.transform('min')) / \\\n",
    "                             (g.transform('max') - g.transform('min'))\n",
    "\n",
    "# max=min → 모든 월 평균이 동일 → 1로 통일\n",
    "menu_month_avg.loc[g.transform('max') == g.transform('min'), 'month_score'] = 1.0\n",
    "\n",
    "# 원본 데이터에 merge\n",
    "train = train.merge(\n",
    "    menu_month_avg[['영업장명_메뉴명','month','month_score']],\n",
    "    on=['영업장명_메뉴명','month'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "id": "4851e23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0/1로 되어 있다고 가정: non_work = (주말 or 휴일) 1, 평일 0\n",
    "train['영업일자'] = pd.to_datetime(train['영업일자'])\n",
    "\n",
    "# 1) 날짜 단위 non_work(하루에 여러 행이면 max로 대표)\n",
    "daily = (\n",
    "    train.groupby('영업일자', as_index=False)\n",
    "         .agg({\n",
    "             'non_work': 'max',     # 하루에 하나라도 주말/휴일이면 1\n",
    "             'is_holiday': 'max'    # 하루에 하나라도 휴일이면 1\n",
    "         })\n",
    "         .sort_values('영업일자')\n",
    ")\n",
    "\n",
    "# 2) 날짜 기준으로 before/after 플래그 계산\n",
    "daily['is_before_holiday'] = (\n",
    "    (daily['non_work'].eq(0)) &\n",
    "    (daily['non_work'].shift(-1, fill_value=0).eq(1))\n",
    ").astype(int)\n",
    "\n",
    "daily['is_after_holiday'] = (\n",
    "    (daily['non_work'].eq(0)) &\n",
    "    (daily['non_work'].shift(1, fill_value=0).eq(1)) &\n",
    "    (daily['is_holiday'].shift(1, fill_value=0).eq(1))\n",
    ").astype(int)\n",
    "\n",
    "# 3) 원본 train에 날짜로 merge\n",
    "train = train.merge(\n",
    "    daily[['영업일자', 'is_before_holiday', 'is_after_holiday']],\n",
    "    on='영업일자', how='left'\n",
    ")\n",
    "\n",
    "# 필요하면 non_work 컬럼 정리\n",
    "train = train.drop(columns=['non_work'], errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423b0a37",
   "metadata": {},
   "source": [
    "# menu_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "id": "ae30ef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시: train 데이터에 영업장명, 메뉴명, 매출수량 컬럼이 있다고 가정\n",
    "# train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# 1) 영업장별 메뉴별 총매출\n",
    "menu_sales = (\n",
    "    train.groupby(['영업장명', '메뉴명'], as_index=False)['매출수량']\n",
    "         .sum()\n",
    "         .rename(columns={'매출수량': '총매출수량'})\n",
    ")\n",
    "\n",
    "# 2) 영업장 안에서 순위(내림차순: 많이 팔린 메뉴가 1위)\n",
    "menu_sales['rank'] = menu_sales.groupby('영업장명')['총매출수량'] \\\n",
    "                               .rank(method='average', ascending=False)\n",
    "\n",
    "# 3) 영업장별 메뉴 개수\n",
    "menu_sales['n'] = menu_sales.groupby('영업장명')['총매출수량'].transform('size')\n",
    "\n",
    "# 4) 0~1 스케일: (n - rank) / (n - 1)\n",
    "#    → rank=1이면 1, rank=n이면 0 (n=1인 경우 예외 처리)\n",
    "menu_sales['rank01'] = (menu_sales['n'] - menu_sales['rank']) / (menu_sales['n'] - 1)\n",
    "menu_sales.loc[menu_sales['n'] == 1, 'rank01'] = 1.0  # 해당 영업장에 메뉴가 1개뿐이면 1\n",
    "\n",
    "# 5) 원본 train에 붙이기\n",
    "train = train.merge(\n",
    "    menu_sales[['영업장명', '메뉴명', 'rank01']], \n",
    "    on=['영업장명', '메뉴명'], how='left'\n",
    ").rename(columns={'rank01': 'menu_rank'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aea23ce",
   "metadata": {},
   "source": [
    "# menu_ category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "id": "5a8b884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_category = {\n",
    "    '1인 수저세트': '기타',\n",
    "    'BBQ55(단체)': '메인메뉴',\n",
    "    '대여료 60,000원': '기타',\n",
    "    '대여료 30,000원': '기타',\n",
    "       '대여료 90,000원': '기타',\n",
    "       '본삼겹 (단품,실내)': '메인메뉴',\n",
    "       '스프라이트 (단체)': '음료',\n",
    "       '신라면': '추가메뉴',\n",
    "       '쌈야채세트': '추가메뉴',\n",
    "       '쌈장': '추가메뉴',\n",
    "       '육개장 사발면': '추가메뉴',\n",
    "       '일회용 소주컵': '기타',\n",
    "       '일회용 종이컵': '기타',\n",
    "       '잔디그늘집 대여료 (12인석)': '기타',\n",
    "       '잔디그늘집 대여료 (6인석)': '기타',\n",
    "       '잔디그늘집 의자 추가': '기타',\n",
    "       '참이슬 (단체)': '주류',\n",
    "       '친환경 접시 14cm': '기타',\n",
    "       '친환경 접시 23cm': '기타',\n",
    "       '카스 병(단체)': '주류',\n",
    "       '콜라 (단체)': '음료',\n",
    "       '햇반': '추가메뉴',\n",
    "       '허브솔트': '추가메뉴',\n",
    "       '(단체) 공깃밥': '추가메뉴',\n",
    "       '(단체) 생목살 김치전골 2.0': '메인메뉴',\n",
    "       '(단체) 은이버섯 갈비탕': '메인메뉴',\n",
    "       '(단체) 한우 우거지 국밥': '메인메뉴',\n",
    "       '(단체) 황태해장국 3/27까지': '메인메뉴',\n",
    "       '(정식) 된장찌개': '메인메뉴',\n",
    "       '(정식) 물냉면 ': '메인메뉴',\n",
    "       '(정식) 비빔냉면': '메인메뉴',\n",
    "       '(후식) 된장찌개': '추가메뉴',\n",
    "       '(후식) 물냉면': '추가메뉴',\n",
    "       '(후식) 비빔냉면': '추가메뉴',\n",
    "       '갑오징어 비빔밥': '메인메뉴',\n",
    "       '갱시기': '메인메뉴',\n",
    "       '공깃밥': '추가메뉴',\n",
    "       '꼬막 비빔밥': '메인메뉴',\n",
    "       '느린마을 막걸리': '주류',\n",
    "       '담하 한우 불고기': '메인메뉴',\n",
    "       '담하 한우 불고기 정식': '메인메뉴',\n",
    "       '더덕 한우 지짐': '메인메뉴',\n",
    "       '들깨 양지탕': '메인메뉴',\n",
    "       '라면사리': '추가메뉴',\n",
    "       '룸 이용료': '기타',\n",
    "       '메밀면 사리': '추가메뉴',\n",
    "       '명인안동소주': '주류',\n",
    "       '명태회 비빔냉면': '메인메뉴',\n",
    "       '문막 복분자 칵테일': '주류',\n",
    "       '봉평메밀 물냉면': '메인메뉴',\n",
    "       '생목살 김치찌개': '메인메뉴',\n",
    "       '스프라이트': '음료',\n",
    "       '은이버섯 갈비탕': '메인메뉴',\n",
    "       '제로콜라': '음료',\n",
    "       '참이슬': '주류',\n",
    "       '처음처럼': '주류',\n",
    "       '카스': '주류',\n",
    "       '콜라': '음료',\n",
    "       '테라': '주류',\n",
    "       '하동 매실 칵테일': '주류',\n",
    "       '한우 떡갈비 정식': '메인메뉴',\n",
    "       '한우 미역국 정식': '메인메뉴',\n",
    "       '한우 우거지 국밥': '메인메뉴',\n",
    "       '한우 차돌박이 된장찌개': '메인메뉴',\n",
    "       '황태해장국': '메인메뉴',\n",
    "       'AUS (200g)': '메인메뉴',\n",
    "       'G-Charge(3)': '기타',\n",
    "       'Gls.Sileni': '주류',\n",
    "       'Gls.미션 서드': '주류',\n",
    "       'Open Food': '기타',\n",
    "       '그릴드 비프 샐러드': '메인메뉴',\n",
    "       '까르보나라': '메인메뉴',\n",
    "       '모둠 해산물 플래터': '메인메뉴',\n",
    "       '미션 서드 카베르네 쉬라': '메인메뉴',\n",
    "       '버섯 크림 리조또': '메인메뉴',\n",
    "       '빵 추가 (1인)': '추가메뉴',\n",
    "       '시저 샐러드 ': '메인메뉴',\n",
    "       '아메리카노': '음료',\n",
    "       '알리오 에 올리오 ': '메인메뉴',\n",
    "       '양갈비 (4ps)': '메인메뉴',\n",
    "       '자몽리치에이드': '음료',\n",
    "       '하이네켄(생)': '주류',\n",
    "       '한우 (200g)': '메인메뉴',\n",
    "       '해산물 토마토 리조또': '메인메뉴',\n",
    "       '해산물 토마토 스튜 파스타': '메인메뉴',\n",
    "       '해산물 토마토 스파게티': '메인메뉴',\n",
    "       '(단체)브런치주중 36,000': '메인메뉴',\n",
    "       '(오븐) 하와이안 쉬림프 피자': '메인메뉴',\n",
    "       '(화덕) 불고기 페퍼로니 반반피자': '메인메뉴',\n",
    "       'BBQ Platter': '메인메뉴',\n",
    "       'BBQ 고기추가': '추가메뉴',\n",
    "       '글라스와인 (레드)': '주류',\n",
    "       '레인보우칵테일(알코올)': '주류',\n",
    "       '미라시아 브런치 (패키지)': '메인메뉴',\n",
    "       '버드와이저(무제한)': '주류',\n",
    "       '보일링 랍스타 플래터': '메인메뉴',\n",
    "       '보일링 랍스타 플래터(덜매운맛)': '메인메뉴',\n",
    "       '브런치 2인 패키지 ': '메인메뉴',\n",
    "       '브런치 4인 패키지 ': '메인메뉴',\n",
    "       '브런치(대인) 주말': '메인메뉴',\n",
    "       '브런치(대인) 주중': '메인메뉴',\n",
    "       '브런치(어린이)': '메인메뉴',\n",
    "       '쉬림프 투움바 파스타': '메인메뉴',\n",
    "       '스텔라(무제한)': '주류',\n",
    "       '애플망고 에이드': '음료',\n",
    "       '얼그레이 하이볼': '주류',\n",
    "       '오븐구이 윙과 킬바사소세지': '메인메뉴',\n",
    "       '유자 하이볼': '주류',\n",
    "       '잭 애플 토닉': '주류',\n",
    "       '칠리 치즈 프라이': '추가메뉴',\n",
    "       '코카콜라': '음료',\n",
    "       '코카콜라(제로)': '음료',\n",
    "       '콥 샐러드': '추가메뉴',\n",
    "       '파스타면 추가(150g)': '추가메뉴',\n",
    "       '핑크레몬에이드': '음료',\n",
    "       'Cass Beer': '주류',\n",
    "       'Conference L1': '연회장 대여',\n",
    "       'Conference L2': '연회장 대여',\n",
    "       'Conference L3': '연회장 대여',\n",
    "       'Conference M1': '연회장 대여',\n",
    "       'Conference M8': '연회장 대여',\n",
    "       'Conference M9': '연회장 대여',\n",
    "       'Convention Hall': '연회장 대여',\n",
    "       'Cookie Platter': '디저트',\n",
    "       'Grand Ballroom': '연회장 대여',\n",
    "       'OPUS 2': '연회장 대여',\n",
    "       'Regular Coffee': '음료',\n",
    "       '골뱅이무침': '메인메뉴',\n",
    "       '돈목살 김치찌개 (밥포함)': '메인메뉴',\n",
    "       '로제 치즈떡볶이': '메인메뉴',\n",
    "       '마라샹궈': '메인메뉴',\n",
    "       '매콤 무뼈닭발&계란찜': '메인메뉴',\n",
    "       '모둠 돈육구이(3인)': '메인메뉴',\n",
    "       '삼겹살추가 (200g)': '추가메뉴',\n",
    "       '야채추가': '추가메뉴',\n",
    "       '왕갈비치킨': '메인메뉴',\n",
    "       '주먹밥 (2ea)': '추가메뉴',\n",
    "       '공깃밥(추가)': '추가메뉴',\n",
    "       '구슬아이스크림': '디저트',\n",
    "       '단체식 13000(신)': '메인메뉴',\n",
    "       '단체식 18000(신)': '메인메뉴',\n",
    "       '돼지고기 김치찌개': '메인메뉴',\n",
    "       '복숭아 아이스티': '음료',\n",
    "       '새우 볶음밥': '메인메뉴',\n",
    "       '새우튀김 우동': '메인메뉴',\n",
    "       '샷 추가': '추가메뉴',\n",
    "       '수제 등심 돈까스': '메인메뉴',\n",
    "       '아메리카노(HOT)': '음료',\n",
    "       '아메리카노(ICE)': '음료',\n",
    "       '약 고추장 돌솥비빔밥': '메인메뉴',\n",
    "       '어린이 돈까스': '메인메뉴',\n",
    "       '오픈푸드': '기타',\n",
    "       '진사골 설렁탕': '메인메뉴',\n",
    "       '짜장면': '메인메뉴',\n",
    "       '짜장밥': '메인메뉴',\n",
    "       '짬뽕': '메인메뉴',\n",
    "       '짬뽕밥': '메인메뉴',\n",
    "       '치즈돈까스': '메인메뉴',\n",
    "       '카페라떼(HOT)': '음료',\n",
    "       '카페라떼(ICE)': '음료',\n",
    "       '한상 삼겹구이 정식(2인) 소요시간 약 15~20분': '메인메뉴',\n",
    "       '꼬치어묵': '메인메뉴',\n",
    "       '떡볶이': '메인메뉴',\n",
    "       '생수': '음료',\n",
    "       '치즈 핫도그': '디저트',\n",
    "       '페스츄리 소시지': '디저트',\n",
    "       '단호박 식혜 ': '음료',\n",
    "       '병천순대': '메인메뉴',\n",
    "       '참살이 막걸리': '주류',\n",
    "       '찹쌀식혜': '음료',\n",
    "       '해물파전': '메인메뉴',\n",
    "       '메밀미숫가루': '음료',\n",
    "       '아메리카노 HOT': '음료',\n",
    "       '아메리카노 ICE': '음료',\n",
    "       '카페라떼 ICE': '음료',\n",
    "       '현미뻥스크림': '디저트'\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "id": "6bad37ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the menu_category to df\n",
    "train['menu_category'] = train['메뉴명'].map(menu_category)\n",
    "train['menu_category'], uniques = pd.factorize(train['menu_category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4515de",
   "metadata": {},
   "source": [
    "# avg_sales_all_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "id": "1bee03a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_avg = train.groupby('메뉴명')['매출수량'].mean()\n",
    "train['avg_sales_all_days'] = train['메뉴명'].map(menu_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8f169d",
   "metadata": {},
   "source": [
    "# solar_term, season, quarter\n",
    "1. solar_term, solar_term_sum\n",
    "2. season, season_sum\n",
    "3. quarter, quarter_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "id": "ebadecc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_solar_term(\n",
    "    train: pd.DataFrame,\n",
    "    terms: pd.DataFrame,\n",
    "    date_col: str = \"영업일자\",\n",
    "    term_date_col: str = \"locdate\",\n",
    "    term_name_col: str = \"solar_term\",\n",
    "    out_col: str = \"solar_term\"\n",
    ") -> pd.DataFrame:\n",
    "    df = train.copy()\n",
    "    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "    terms = terms.copy()\n",
    "    terms[term_date_col] = pd.to_datetime(terms[term_date_col], errors='coerce')\n",
    "\n",
    "    # 절기 구간 만들기\n",
    "    terms = terms.sort_values(term_date_col).reset_index(drop=True)\n",
    "    terms['end_date'] = terms[term_date_col].shift(-1) - pd.Timedelta(days=1)\n",
    "    terms.loc[terms.index[-1], 'end_date'] = df[date_col].max()\n",
    "\n",
    "    # ★ 절기명 컬럼을 임시 이름으로 바꿔서 머지\n",
    "    tmp_col = \"_term_name_tmp\"\n",
    "    right = terms[[term_date_col, term_name_col, 'end_date']].rename(columns={term_name_col: tmp_col})\n",
    "\n",
    "    merged = pd.merge_asof(\n",
    "        df.sort_values(date_col),\n",
    "        right.sort_values(term_date_col),\n",
    "        left_on=date_col,\n",
    "        right_on=term_date_col,\n",
    "        direction='backward'\n",
    "    )\n",
    "\n",
    "    in_range = merged[date_col] <= merged['end_date']\n",
    "    merged[out_col] = merged[tmp_col].where(in_range)\n",
    "\n",
    "    # 임시 컬럼만 삭제 (out_col은 유지)\n",
    "    merged = merged.drop(columns=[term_date_col, 'end_date', tmp_col]).sort_index()\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "id": "15f248a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 0) 날짜 보정\n",
    "# if df['영업일자'].dtype == 'O':\n",
    "#     df['영업일자'] = pd.to_datetime(df['영업일자'], errors='coerce')\n",
    "\n",
    "# 1) '분기' → 'quarter'로 변경 (없으면 새로 생성)\n",
    "#     Q1, Q2, Q3, Q4 형식으로 생성\n",
    "def get_quarter_code(m):\n",
    "        if m in (1,2,3): return 0\n",
    "        if m in (4,5,6): return 1\n",
    "        if m in (7,8,9): return 2\n",
    "        return 3\n",
    "train['quarter'] = train['month'].apply(get_quarter_code)\n",
    "train['season'] = train.apply(\n",
    "    lambda x: 0 if x['month'] in [3, 4, 5] else\n",
    "              (1 if x['month'] in [6, 7, 8] else\n",
    "               (2 if x['month'] in [9, 10, 11] else 3)),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# terms 예시: columns=['locdate','절기'] 라면 term_name_col='절기'로 지정\n",
    "train = attach_solar_term(\n",
    "    train,\n",
    "    terms,                   # 절기 lookup DF\n",
    "    date_col=\"영업일자\",\n",
    "    term_date_col=\"locdate\",\n",
    "    term_name_col=\"solar_term\",    # 실제 컬럼명 맞추기!\n",
    "    out_col=\"solar_term\"     # train에 새로 생길 이름\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "id": "70275aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumsum(train, col, newcol):    \n",
    "# 0) 날짜 보정\n",
    "    if train['영업일자'].dtype == 'O':\n",
    "        train['영업일자'] = pd.to_datetime(train['영업일자'], errors='coerce')\n",
    "\n",
    "    # 2) 임시로 매장/메뉴 분리(컬럼 추가 X)\n",
    "    keys = train['영업장명_메뉴명'].str.split('_', n=1, expand=True)\n",
    "    g_store, g_menu = keys[0], keys[1]\n",
    "\n",
    "    # 3) 그룹별 전일까지 누적합 → 전체 열에 한 번에 대입 (정수 고정)\n",
    "    #    - 정렬은 누적 순서만 위해 잠깐 사용, 결과는 원래 인덱스로 돌아옴\n",
    "    train_sorted = train.sort_values([col, '영업일자']).copy()\n",
    "    seasonal_series = (\n",
    "        train_sorted\n",
    "        .groupby([g_store.reindex(train_sorted.index),\n",
    "                    g_menu.reindex(train_sorted.index),\n",
    "                    train_sorted[col]], sort=False)['매출수량']\n",
    "        .transform(lambda s: s.shift(1).cumsum())\n",
    "    )\n",
    "\n",
    "    train[newcol] = (\n",
    "        seasonal_series.reindex(train_sorted.index)\n",
    "                    .reindex(train.index)\n",
    "                    .fillna(0)\n",
    "                    .astype('int64')\n",
    "    )\n",
    "    return train\n",
    "train = cumsum(train, 'quarter', 'quarter_sum')\n",
    "train = cumsum(train, 'season', 'season_sum')\n",
    "train = cumsum(train, 'solar_term', 'solar_term_sum')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af3dbd6",
   "metadata": {},
   "source": [
    "# Feature about zero\n",
    "1. avg_sales_nonzero_days\n",
    "2. avg_sales_nonzero_monthly\n",
    "3. var_sales_nonzero_monthly\n",
    "4. zero_sales_day_ratio\n",
    "5. avg_sales_nonzero_seasonly\n",
    "6. avg_sales_nonzero_weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "id": "9346d862",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_avg = train[train['매출수량'] > 0].groupby('메뉴명')['매출수량'].mean()\n",
    "# Assign the nonzero_avg to df\n",
    "train['avg_sales_nonzero_days'] = train['메뉴명'].map(nonzero_avg)\n",
    "# 매출수량 > 0인 경우만 메뉴별 분산 계산\n",
    "nonzero_var = (\n",
    "    train[train['매출수량'] > 0]\n",
    "    .groupby('메뉴명')['매출수량']\n",
    "    .var()   # ← 분산\n",
    ")\n",
    "nonzero_avg_monthly = (\n",
    "    train[train['매출수량'] > 0]\n",
    "    .groupby(['메뉴명', 'year', 'month'])['매출수량']\n",
    "    .mean()\n",
    "    .rename('avg_sales_nonzero_monthly')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "train = train.merge(nonzero_avg_monthly, on=['메뉴명', 'year', 'month'], how='left')\n",
    "train['avg_sales_nonzero_monthly'] = train['avg_sales_nonzero_monthly'].fillna(0)\n",
    "\n",
    "# train에 새로운 칼럼으로 추가\n",
    "train['var_sales_nonzero_days'] = train['메뉴명'].map(nonzero_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "id": "3600cf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_ratio = train.groupby('메뉴명')['매출수량'].apply(lambda x: (x.eq(0).sum() / len(x)) * 100)\n",
    "\n",
    "# Assign the zero_ratio to df\n",
    "train['zero_sales_day_ratio'] = train['메뉴명'].map(zero_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "id": "b46f9605",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_avg_seasonly = (\n",
    "    train[train['매출수량'] > 0]\n",
    "    .groupby(['메뉴명', 'season'])['매출수량']\n",
    "    .mean()\n",
    "    .rename('avg_sales_nonzero_seasonly')\n",
    ")\n",
    "train = train.merge(nonzero_avg_seasonly, on=['메뉴명', 'season'], how='left')\n",
    "nonzero_avg_weekday = (\n",
    "    train[train['매출수량'] > 0]\n",
    "    .groupby(['메뉴명', 'weekday'])['매출수량']\n",
    "    .mean()\n",
    "    .rename('avg_sales_nonzero_weekday')\n",
    ")\n",
    "train = train.merge(nonzero_avg_weekday, on=['메뉴명', 'weekday'], how='left')\n",
    "train['avg_sales_nonzero_weekday'] = train['avg_sales_nonzero_weekday'].fillna(0)\n",
    "train['avg_sales_nonzero_seasonly'] = train['avg_sales_nonzero_weekday'].fillna(0)\n",
    "\n",
    "train = train.sort_values(['영업장명_메뉴명', '영업일자']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aec5dbe",
   "metadata": {},
   "source": [
    "# demand_volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "id": "779a5d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_stats=(\n",
    "    train.groupby('영업장명_메뉴명')['매출수량']\n",
    "    .agg(['mean','std'])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "menu_stats['demand_volatility']=menu_stats['std']/menu_stats['mean']\n",
    "\n",
    "menu_stats.rename(columns={'mean':'평균매출수량','std':'표준편차'},inplace=True)\n",
    "\n",
    "# Merge menu_stats back to df\n",
    "train=train.merge(menu_stats[['영업장명_메뉴명', 'demand_volatility']], on='영업장명_메뉴명',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef6582e",
   "metadata": {},
   "source": [
    "# date_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "id": "b170e6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3t/x_vcdczj5fn_v1nnkppzjpwh0000gn/T/ipykernel_10003/3133154072.py:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('영업장명', group_keys=False).apply(mark_sandwich_adjacent)\n"
     ]
    }
   ],
   "source": [
    "train = train.sort_values(['영업장명_메뉴명', '영업일자']).reset_index(drop=True)\n",
    "df = train.copy().sort_values(['영업장명_메뉴명','영업일자']).reset_index(drop=True)\n",
    "# 필요 컬럼 가정: ['영업장명','영업일자','is_holiday','is_weekend','weekday','month','day']\n",
    "# weekday: 월=0, 화=1, ... 일=6\n",
    "\n",
    "# ─────────────────────────────────────────────────────\n",
    "# 보조 플래그: 영업장별로 sandwich / adjacent 계산\n",
    "# ─────────────────────────────────────────────────────\n",
    "df['is_special'] = ((df['is_holiday']==1) | (df['is_weekend']==1)).astype(int)\n",
    "\n",
    "def mark_sandwich_adjacent(g: pd.DataFrame) -> pd.DataFrame:\n",
    "    prev_special = g['is_special'].shift(1, fill_value=0)\n",
    "    next_special = g['is_special'].shift(-1, fill_value=0)\n",
    "    g['is_sandwich'] = ((prev_special.eq(1)) & (g['is_special'].eq(0)) & (next_special.eq(1))).astype(int)\n",
    "    g['is_adjacent'] = ((g['is_special'].eq(0)) & (prev_special.eq(1) | next_special.eq(1))).astype(int)\n",
    "    return g\n",
    "\n",
    "df = df.groupby('영업장명', group_keys=False).apply(mark_sandwich_adjacent)\n",
    "\n",
    "# ─────────────────────────────────────────────────────\n",
    "# 규칙 → 마스크 빌더\n",
    "# ─────────────────────────────────────────────────────\n",
    "def build_mask(name: str, g: pd.DataFrame, rule: dict):\n",
    "    \"\"\"name 키워드와 rule 파라미터로 boolean mask 생성\"\"\"\n",
    "    if name == 'holiday':\n",
    "        return g['is_holiday'].eq(1)\n",
    "    if name == 'weekend':\n",
    "        return (g['is_holiday'].eq(0) & g['is_weekend'].eq(1))\n",
    "    if name == 'sandwich':\n",
    "        return (g['is_holiday'].eq(0) & g['is_weekend'].eq(0) & g['is_sandwich'].eq(1))\n",
    "    if name == 'adjacent':\n",
    "        return (g['is_holiday'].eq(0) & g['is_weekend'].eq(0) & g['is_adjacent'].eq(1))\n",
    "    if name == 'friday':\n",
    "        return (g['is_holiday'].eq(0) & g['is_weekend'].eq(0) & g['weekday'].eq(4))\n",
    "    if name == 'tuewedthu':\n",
    "        return (g['is_holiday'].eq(0) & g['is_weekend'].eq(0) & g['weekday'].isin([1,2,3]))\n",
    "    if name == 'monday':\n",
    "        return (g['is_holiday'].eq(0) & g['is_weekend'].eq(0) & g['weekday'].eq(0))\n",
    "    if name == 'weekday_in':\n",
    "        days = rule.get('days', [])\n",
    "        return (g['is_holiday'].eq(0) & g['is_weekend'].eq(0) & g['weekday'].isin(days))\n",
    "    if name == 'custom_mask':\n",
    "        return rule['func'](g)\n",
    "\n",
    "    # ---- 여기부터 추가된 복합 규칙들 ----\n",
    "    # 화~금 (평일만, 휴일/주말 제외)\n",
    "    if name == 'tuewedthufri':\n",
    "        return (g['is_holiday'].eq(0) & g['is_weekend'].eq(0) & g['weekday'].isin([1,2,3,4]))\n",
    "    # 월~목 (평일만, 휴일/주말 제외)\n",
    "    if name == 'montuewedthu':\n",
    "        return (g['is_holiday'].eq(0) & g['is_weekend'].eq(0) & g['weekday'].isin([0,1,2,3]))\n",
    "    # 목/금 (휴일 여부 무관하게 요일만 기준; 위에서 공휴일이 먼저 매칭되므로 충돌 없음)\n",
    "    if name == 'thufri':\n",
    "        return g['weekday'].isin([3,4])\n",
    "    # 화/토 (토요일은 주말이지만, 휴일은 제외하여 공휴일 규칙 우선)\n",
    "    if name == 'tuesat':\n",
    "        return (g['is_holiday'].eq(0) & g['weekday'].isin([1,5]))\n",
    "    # 월/화/수/토/일 (휴일 제외; 연회장/BBQ용)\n",
    "    if name == 'montuewedsatsun':\n",
    "        return (g['is_holiday'].eq(0) & g['weekday'].isin([0,1,2,5,6]))\n",
    "    # 월/일 (휴일 제외)\n",
    "    if name == 'monsun':\n",
    "        return (g['is_holiday'].eq(0) & g['weekday'].isin([0,6]))\n",
    "\n",
    "    raise ValueError(f\"Unknown rule name: {name}\")\n",
    "\n",
    "def apply_date_rules(g: pd.DataFrame, rules: list, default_val: float=1.0) -> pd.Series:\n",
    "    \"\"\"우선순위대로 date_mult를 채움\"\"\"\n",
    "    out = pd.Series(default_val, index=g.index, dtype=float)\n",
    "    assigned = pd.Series(False, index=g.index)\n",
    "    for r in rules:\n",
    "        name = r['name']\n",
    "        mult = r['mult']\n",
    "        mask = build_mask(name, g, r) & (~assigned)\n",
    "        out.loc[mask] = mult\n",
    "        assigned.loc[mask] = True\n",
    "    return out\n",
    "\n",
    "def apply_month_rules(g: pd.DataFrame, rules: list, default_val: float=1.0) -> pd.Series:\n",
    "    \"\"\"여러 월/일 조건을 병렬로 적용(후속 규칙이 덮어씀)\"\"\"\n",
    "    out = pd.Series(default_val, index=g.index, dtype=float)\n",
    "    for r in rules:\n",
    "        mult = r['mult']\n",
    "        if 'months' in r:\n",
    "            mask = g['month'].isin(r['months'])\n",
    "        elif 'month' in r and ('day_from' in r or 'day_to' in r):\n",
    "            # 단일 월 + 일자 범위\n",
    "            mask = g['month'].eq(r['month'])\n",
    "            if 'day_from' in r:\n",
    "                mask &= g['day'] >= r['day_from']\n",
    "            if 'day_to' in r:\n",
    "                mask &= g['day'] <= r['day_to']\n",
    "        elif 'custom_mask' in r:\n",
    "            mask = r['custom_mask'](g)\n",
    "        else:\n",
    "            continue\n",
    "        out.loc[mask] = mult\n",
    "    return out\n",
    "\n",
    "# ─────────────────────────────────────────────────────\n",
    "# 매장별 CONFIG 예시\n",
    "#   - 이 블록만 채우면 전체 자동\n",
    "# ─────────────────────────────────────────────────────\n",
    "CONFIG = {\n",
    "    # 예시) 포레스트릿\n",
    "    '포레스트릿': {\n",
    "        'date': {\n",
    "            'default': 1.0,\n",
    "            'rules': [\n",
    "                {'name':'holiday',   'mult':1.35},\n",
    "                {'name':'weekend',   'mult':1.20},\n",
    "                {'name':'sandwich',  'mult':1.10},\n",
    "                {'name':'adjacent',  'mult':1.06},\n",
    "                {'name':'friday',    'mult':1.03},\n",
    "                {'name':'tuewedthu', 'mult':1.00},\n",
    "            ]\n",
    "        },\n",
    "        'month': {\n",
    "            'default': 1.0,\n",
    "            'rules': [\n",
    "                {'months':[1,2,12],        'mult':1.20},\n",
    "                {'months':[4,5,6,9,10,11], 'mult':1.10},\n",
    "                {'months':[3,7,8],         'mult':0.92},\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    '카페테리아': {\n",
    "        'date': {\n",
    "            'default': 1.0,\n",
    "            'rules': [\n",
    "                {'name':'holiday',   'mult':1.35},\n",
    "                {'name':'weekend',   'mult':1.20},\n",
    "                {'name':'sandwich',  'mult':1.10},\n",
    "                {'name':'adjacent',  'mult':1.06},\n",
    "                {'name':'friday',    'mult':1.03},\n",
    "                {'name':'tuewedthu', 'mult':1.00},\n",
    "            ]\n",
    "        },\n",
    "        'month': {\n",
    "            'default': 1.0,\n",
    "            'rules': [\n",
    "                {'months':[1,2,12],         'mult':1.20},\n",
    "                {'months':[9,10],           'mult':1.10},\n",
    "                {'months':[3,4,5,6,7,8,11], 'mult':0.92},\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    # (예시) 미라시아 — 규칙이 다르다고 가정\n",
    "    '화담숲주막': {\n",
    "        'date': {\n",
    "            'default': 1.0,\n",
    "            'rules': [\n",
    "                {'name':'holiday',   'mult':1.35},   # 공휴일 더 강하게\n",
    "                {'name':'weekend',   'mult':1.20},\n",
    "                {'name':'sandwich',  'mult':1.10},\n",
    "                {'name':'adjacent',  'mult':1.06},\n",
    "                {'name':'tuewedthufri', 'mult':1.00},\n",
    "                {'name':'monday',    'mult':0.97},   # 월요일 약세 반영\n",
    "            ]\n",
    "        },\n",
    "        'month': {\n",
    "            'default': 1.0,\n",
    "            'rules': [\n",
    "                {'months':[4,5,6,10,11],         'mult':1.20},\n",
    "                {'months':[7,8,9],           'mult':1.10},\n",
    "                {'months':[1,2,3,12], 'mult':0.92},\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    '화담숲카페': {\n",
    "        'date': {\n",
    "            'default': 1.0,\n",
    "            'rules': [\n",
    "                {'name':'holiday',   'mult':1.35},   # 공휴일 더 강하게\n",
    "                {'name':'weekend',   'mult':1.20},\n",
    "                {'name':'sandwich',  'mult':1.10},\n",
    "                {'name':'adjacent',  'mult':1.06},\n",
    "                {'name':'tuewedthufri', 'mult':1.00},\n",
    "                {'name':'monday',    'mult':0.97},   # 월요일 약세 반영\n",
    "            ]\n",
    "        },\n",
    "        'month': {\n",
    "            'default': 1.0,\n",
    "            'rules': [\n",
    "                {'months':[4,5,6,10,11],         'mult':1.20},\n",
    "                {'months':[7,8,9],           'mult':1.10},\n",
    "                {'months':[1,2,3,12], 'mult':0.92},\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    '미라시아': {\n",
    "        'date': {\n",
    "            'default': 1.0,\n",
    "            'rules': [\n",
    "                {'name':'holiday',   'mult':1.35},   # 공휴일 더 강하게\n",
    "                {'name':'weekend',   'mult':1.20},\n",
    "                {'name':'sandwich',  'mult':1.10},\n",
    "                {'name':'adjacent',  'mult':1.06},\n",
    "                {'name':'friday', 'mult':1.03},\n",
    "                {'name':'montuewedthu',    'mult':1.00},   # 월요일 약세 반영\n",
    "            ]\n",
    "        },\n",
    "        'month': {\n",
    "            'default': 1.0,\n",
    "            'rules': [\n",
    "                {'months':[1,2,9,10,11],         'mult':1.20},\n",
    "                {'months':[8],           'mult':1.10},\n",
    "                {'months':[4,5,6,7,12], 'mult':1.05},\n",
    "                {'months':[3], 'mult':0.92},\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    '담하': {\n",
    "        'date': {\n",
    "            'default': 1.0,\n",
    "            'rules': [\n",
    "                {'name':'holiday',   'mult':1.35},   # 공휴일 더 강하게\n",
    "                {'name':'weekend',   'mult':1.20},\n",
    "                {'name':'sandwich',  'mult':1.10},\n",
    "                {'name':'adjacent',  'mult':1.06},\n",
    "                {'name':'friday', 'mult':1.03},\n",
    "                {'name':'montuewedthu',    'mult':1.00},   # 월요일 약세 반영\n",
    "            ]\n",
    "        },\n",
    "        'month': {\n",
    "            'default': 1.0,\n",
    "            'rules': [\n",
    "                {'months':[1,2,10,11],         'mult':1.20},\n",
    "                {'months':[4,5,6,7,8,9,12], 'mult':1.10},\n",
    "                {'months':[3], 'mult':0.92},\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    '라그로타': {\n",
    "        'date': {\n",
    "            'default': 1.0,\n",
    "            'rules': [\n",
    "                {'name':'holiday',   'mult':1.35},   # 공휴일 더 강하게\n",
    "                {'name':'weekend',   'mult':1.20},\n",
    "                {'name':'sandwich',  'mult':1.10},\n",
    "                {'name':'adjacent',  'mult':1.06},\n",
    "                {'name':'friday', 'mult':1.03},\n",
    "                {'name':'tuewedthu',    'mult':1.00},   # 월요일 약세 반영\n",
    "                {'name':'monday',    'mult':0.97},   # 월요일 약세 반영\n",
    "            ]\n",
    "        },\n",
    "        'month': {\n",
    "            'default': 1.0,\n",
    "            'rules': [\n",
    "                {'months':[1,2,12],         'mult':1.20},\n",
    "                {'months':[4,5,6,7,8,9,10,11], 'mult':1.10},\n",
    "                {'months':[3], 'mult':0.92},\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    '느티나무 셀프BBQ': {\n",
    "        'date': {\n",
    "            'default': 1.0,\n",
    "            'rules': [\n",
    "                {'name':'thufri',   'mult':1.20},   # 공휴일 더 강하게\n",
    "                {'name':'montuewedsatsun',   'mult':1.00},\n",
    "            ]\n",
    "        },\n",
    "        'month': {\n",
    "            'default': 1.0,\n",
    "            'rules': [\n",
    "                {'months':[4,5,6,7,9,10,11,12],         'mult':1.20},\n",
    "                {'months':[1,2,3,8], 'mult':1.00},\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    '연회장': {\n",
    "        'date': {\n",
    "            'default': 1.0,\n",
    "            'rules': [\n",
    "                {'name':'thufri',   'mult':1.20},   # 공휴일 더 강하게\n",
    "                {'name':'tuesat',   'mult':1.10},\n",
    "                {'name':'monsun',   'mult':1.00},\n",
    "            ]\n",
    "        },\n",
    "        'month': {\n",
    "            'default': 1.0,\n",
    "            'rules': [\n",
    "                {'months':[1,2,3,4,5,6,7,8,9,10,11,12], 'mult':1.00},\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "}\n",
    "\n",
    "# ─────────────────────────────────────────────────────\n",
    "# 적용\n",
    "# ─────────────────────────────────────────────────────\n",
    "df['date_mult']  = 1.0\n",
    "df['month_mult'] = 1.0\n",
    "\n",
    "\n",
    "\n",
    "for store, g in df.groupby('영업장명'):\n",
    "    if store not in CONFIG:\n",
    "        raise KeyError(f\"CONFIG에 '{store}'가 없습니다.\")\n",
    "    conf = CONFIG[store]\n",
    "    date_mult  = apply_date_rules(g, conf['date']['rules'],  conf['date'].get('default', 1.0))\n",
    "    month_mult = apply_month_rules(g, conf['month']['rules'], conf['month'].get('default', 1.0))\n",
    "    df.loc[g.index, 'date_mult']  = date_mult.values\n",
    "    df.loc[g.index, 'month_mult'] = month_mult.values\n",
    "    \n",
    "\n",
    "# 최종 배수 및 안정화\n",
    "df['date_weight'] = (df['date_mult'] * df['month_mult']).clip(0.7, 1.6)\n",
    "\n",
    "train = train.sort_values(['영업장명_메뉴명', '영업일자']).reset_index(drop=True)\n",
    "\n",
    "# 결과\n",
    "train['date_weight'] = df['date_weight'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86991e69",
   "metadata": {},
   "source": [
    "# menu_date_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "id": "fcd04da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3t/x_vcdczj5fn_v1nnkppzjpwh0000gn/T/ipykernel_10003/2826190629.py:31: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  weighted = merged.groupby('영업장명_메뉴명', group_keys=False).apply(scale_1_2)\n",
      "/var/folders/3t/x_vcdczj5fn_v1nnkppzjpwh0000gn/T/ipykernel_10003/2826190629.py:73: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  weighted = merged.groupby('영업장명_메뉴명', group_keys=False).apply(scale_1_2)\n"
     ]
    }
   ],
   "source": [
    "def build_weight_map_from_train(df_train: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    입력 df_train에는 '영업일자', '영업장명_메뉴명', '매출수량' 컬럼이 있어야 한다.\n",
    "    산출물은 (영업장명_메뉴명, weekday, weekday_weight) 매핑 테이블.\n",
    "    \"\"\"\n",
    "    df = df_train.copy()\n",
    "\n",
    "    # 메뉴×요일 평균\n",
    "    by_wk = (df.groupby(['영업장명_메뉴명','weekday'], as_index=False)['매출수량']\n",
    "               .mean()\n",
    "               .rename(columns={'매출수량':'wk_mean'}))\n",
    "\n",
    "    # 메뉴 전체 평균\n",
    "    by_menu = (df.groupby('영업장명_메뉴명', as_index=False)['매출수량']\n",
    "                 .mean()\n",
    "                 .rename(columns={'매출수량':'overall_mean'}))\n",
    "\n",
    "    merged = by_wk.merge(by_menu, on='영업장명_메뉴명', how='left')\n",
    "    merged['dev'] = merged['wk_mean'] - merged['overall_mean']  # 방향성 있는 편차\n",
    "\n",
    "    # 메뉴 내부에서 1~2 스케일\n",
    "    def scale_1_2(g):\n",
    "        mn = g['dev'].min()\n",
    "        mx = g['dev'].max()\n",
    "        if np.isclose(mx, mn):\n",
    "            g['weekday_weight'] = 1.0  # 전부 동일하면 1.0\n",
    "        else:\n",
    "            g['weekday_weight'] = 1 + (g['dev'] - mn) / (mx - mn)\n",
    "        return g\n",
    "\n",
    "    weighted = merged.groupby('영업장명_메뉴명', group_keys=False).apply(scale_1_2)\n",
    "    weight_map = weighted[['영업장명_메뉴명','weekday','weekday_weight']].copy()\n",
    "\n",
    "    # 안전 검사 (0 금지, NaN 금지)\n",
    "    if (weight_map['weekday_weight'] <= 0).any():\n",
    "        raise ValueError(\"weekday_weight에 0 이하 값이 포함되었습니다. 로직을 점검하세요.\")\n",
    "    if weight_map['weekday_weight'].isna().any():\n",
    "        raise ValueError(\"weekday_weight에 NaN이 포함되었습니다.\")\n",
    "\n",
    "    return weight_map\n",
    "\n",
    "weight_map = build_weight_map_from_train(train)\n",
    "train = train.merge(weight_map, on=['영업장명_메뉴명','weekday'], how='left')\n",
    "\n",
    "def build_month_weight_map_from_train(df_train: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    입력 df_train에는 '영업일자', '영업장명_메뉴명', '매출수량', 'month' 컬럼이 있어야 한다.\n",
    "    산출물은 (영업장명_메뉴명, month, month_weight) 매핑 테이블.\n",
    "    \"\"\"\n",
    "    df = df_train.copy()\n",
    "\n",
    "    # 메뉴×월 평균\n",
    "    by_m = (df.groupby(['영업장명_메뉴명','month'], as_index=False)['매출수량']\n",
    "              .mean()\n",
    "              .rename(columns={'매출수량':'m_mean'}))\n",
    "\n",
    "    # 메뉴 전체 평균\n",
    "    by_menu = (df.groupby('영업장명_메뉴명', as_index=False)['매출수량']\n",
    "                 .mean()\n",
    "                 .rename(columns={'매출수량':'overall_mean'}))\n",
    "\n",
    "    merged = by_m.merge(by_menu, on='영업장명_메뉴명', how='left')\n",
    "    merged['dev'] = merged['m_mean'] - merged['overall_mean']\n",
    "\n",
    "    def scale_1_2(g):\n",
    "        mn, mx = g['dev'].min(), g['dev'].max()\n",
    "        if np.isclose(mx, mn):\n",
    "            g['month_weight'] = 1.0\n",
    "        else:\n",
    "            g['month_weight'] = 1 + (g['dev'] - mn) / (mx - mn)\n",
    "        return g\n",
    "\n",
    "    weighted = merged.groupby('영업장명_메뉴명', group_keys=False).apply(scale_1_2)\n",
    "    weight_map = weighted[['영업장명_메뉴명','month','month_weight']].copy()\n",
    "\n",
    "    if (weight_map['month_weight'] <= 0).any():\n",
    "        raise ValueError(\"month_weight에 0 이하 값이 포함되었습니다.\")\n",
    "    if weight_map['month_weight'].isna().any():\n",
    "        raise ValueError(\"month_weight에 NaN이 포함되었습니다.\")\n",
    "\n",
    "    return weight_map\n",
    "month_weight_map = build_month_weight_map_from_train(train)\n",
    "train = train.merge(month_weight_map, on=['영업장명_메뉴명','month'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "id": "74a07326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weekday_weight × month_weight → menu_date_weight\n",
    "train['menu_date_weight'] = train['weekday_weight'] * train['month_weight']\n",
    "train = train.drop(columns=['weekday_weight','month_weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5487a9",
   "metadata": {},
   "source": [
    "# Store trian.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "id": "8e0703ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['영업일자', '영업장명_메뉴명', '매출수량', 'year', 'month', 'day', '영업장명', '메뉴명',\n",
      "       'weekday', 'is_holiday', 'is_weekend', 'is_sandwich', 'weekday_score',\n",
      "       'month_score', 'is_before_holiday', 'is_after_holiday', 'menu_rank',\n",
      "       'menu_category', 'avg_sales_all_days', 'quarter', 'season',\n",
      "       'solar_term', 'quarter_sum', 'season_sum', 'solar_term_sum',\n",
      "       'avg_sales_nonzero_days', 'avg_sales_nonzero_monthly',\n",
      "       'var_sales_nonzero_days', 'zero_sales_day_ratio',\n",
      "       'avg_sales_nonzero_seasonly', 'avg_sales_nonzero_weekday',\n",
      "       'demand_volatility', 'date_weight', 'menu_date_weight'],\n",
      "      dtype='object')\n",
      "train DataFrame이 output.csv로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "train[['영업장명', '메뉴명']] = train['영업장명_메뉴명'].str.split('_', expand=True)\n",
    "\n",
    "train = train.sort_values(['영업장명_메뉴명', '영업일자']).reset_index(drop=True)\n",
    "train.to_csv(\"train_fin.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(train.columns)\n",
    "\n",
    "print(\"train DataFrame이 output.csv로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708aa8b6",
   "metadata": {},
   "source": [
    "# Task\n",
    "Apply the same feature engineering steps (date features, holiday features, spike/drop, seasonal index, banquet type, etc.) that were applied to the training data to the following test files: \"TEST_01.csv\", \"TEST_02.csv\", \"TEST_03.csv\", \"TEST_04.csv\", \"TEST_05.csv\", \"TEST_06.csv\", \"TEST_07.csv\", \"TEST_08.csv\", \"TEST_09.csv\". Ensure that all engineered features are added as new columns to the respective DataFrames loaded from these files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf9524c",
   "metadata": {},
   "source": [
    "## Identify test files\n",
    "\n",
    "### Subtask:\n",
    "Create a list of all the test file paths (`TEST_01.csv` to `TEST_09.csv`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee7ae7b",
   "metadata": {},
   "source": [
    "**Reasoning**:\n",
    "Create a list containing the file paths for the test datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "id": "c1ddf32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TEST_00.csv', 'TEST_01.csv', 'TEST_02.csv', 'TEST_03.csv', 'TEST_04.csv', 'TEST_05.csv', 'TEST_06.csv', 'TEST_07.csv', 'TEST_08.csv', 'TEST_09.csv']\n"
     ]
    }
   ],
   "source": [
    "test_files = [f\"TEST_{i:02d}.csv\" for i in range(0, 10)] # Changed range from 1 to 0 to include TEST_00\n",
    "print(test_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe34e70",
   "metadata": {},
   "source": [
    "## Define feature engineering function\n",
    "\n",
    "### Subtask:\n",
    "Create a function that takes a DataFrame (like the one loaded from a test file) and applies all the necessary feature engineering steps (date features, holiday features, spike/drop, seasonal index, banquet type, etc.) to it, returning the processed DataFrame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77f4ebe",
   "metadata": {},
   "source": [
    "**Reasoning**:\n",
    "Define a function `engineer_features` that takes a DataFrame and applies all the feature engineering steps. This function will include date features, holiday features, spike/drop detection, weekday/weekend price flags, seasonal index, brunch/hallroom flags, and banquet type merging.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c818d8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df_test, holiday_df, terms_df=None, terms_csv_path=None):\n",
    "    \"\"\"Applies feature engineering steps to a test DataFrame.\n",
    "       terms_df: (선택) 절기 테이블 DataFrame (cols: ['locdate','solar_term'])\n",
    "       terms_csv_path: (선택) terms_df가 없을 때 읽어올 CSV 경로\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    df_test[['영업장명', '메뉴명']] = df_test['영업장명_메뉴명'].str.split('_', expand=True)\n",
    "\n",
    "\n",
    "    # --- 기본 날짜 피처 ---\n",
    "    # year, month, day, weekday\n",
    "    df_test = df_test.copy()\n",
    "    df_test['영업일자'] = pd.to_datetime(df_test['영업일자'], errors='coerce')\n",
    "    df_test['year']    = df_test['영업일자'].dt.year.astype(int)\n",
    "    df_test['month']   = df_test['영업일자'].dt.month.astype(int)\n",
    "    df_test['day']     = df_test['영업일자'].dt.day.astype(int)\n",
    "    df_test['weekday'] = df_test['영업일자'].dt.weekday.astype(int)\n",
    "\n",
    "    # season, quarter, solar_term\n",
    "    def get_season_code(m):\n",
    "        if m in (12,1,2): return 0\n",
    "        if m in (3,4,5):  return 1\n",
    "        if m in (6,7,8):  return 2\n",
    "        return 3\n",
    "    df_test['season'] = df_test['month'].apply(get_season_code)\n",
    "    def get_quarter_code(m):\n",
    "        if m in (1,2,3): return 0\n",
    "        if m in (4,5,6): return 1\n",
    "        if m in (7,8,9): return 2\n",
    "        return 3\n",
    "    df_test['quarter'] = df_test['month'].apply(get_quarter_code)\n",
    "    df_test = attach_solar_term(\n",
    "        df_test,\n",
    "        terms,                   # 절기 lookup DF\n",
    "        date_col=\"영업일자\",\n",
    "        term_date_col=\"locdate\",\n",
    "        term_name_col=\"solar_term\",    # 실제 컬럼명 맞추기!\n",
    "        out_col=\"solar_term\"     # train에 새로 생길 이름\n",
    "    )\n",
    "\n",
    "    # season_sum, quarter_sum, solar_term_sum\n",
    "    def attach_avg_by_keys(train, df_test, value_col, out_col=None,\n",
    "                        keys=('영업장명_메뉴명','month','day')):\n",
    "        # train에서 키별 평균 테이블\n",
    "        mp = (train.groupby(list(keys), as_index=False)[value_col]\n",
    "                    .mean()\n",
    "                    .rename(columns={value_col: out_col or value_col}))\n",
    "        # test에 merge\n",
    "        df_test = df_test.merge(mp, on=list(keys), how='left')\n",
    "        return df_test\n",
    "\n",
    "    # 사용 예시: 각 *_sum 컬럼의 평균을 동일 키로 test에 붙이기\n",
    "    df_test = attach_avg_by_keys(train, df_test, 'season_sum')\n",
    "    df_test = attach_avg_by_keys(train, df_test, 'solar_term_sum')\n",
    "    df_test = attach_avg_by_keys(train, df_test, 'quarter_sum')\n",
    "\n",
    "    # is_holiday, is_weekend, is_sandwich, is_before_holiday, is_after_holiday\n",
    "    holiday_df['locdate'] = pd.to_datetime(holiday_df['locdate'])\n",
    "    df_test = pd.merge(\n",
    "        df_test,\n",
    "        holiday_df[['locdate', 'isHoliday']],\n",
    "        how='left',\n",
    "        left_on='영업일자',\n",
    "        right_on='locdate'\n",
    "    )\n",
    "    df_test['is_holiday'] = df_test['isHoliday'].fillna('N').apply(lambda x: 1 if x == 'Y' else 0)\n",
    "    df_test = df_test.drop(['locdate', 'isHoliday'], axis=1)  # 둘 다 삭제\n",
    "    df_test['is_weekend'] = df_test['weekday'].apply(lambda x: 1 if x in [5, 6] else 0)\n",
    "\n",
    "    df_test[\"non_work\"] = ((df_test[\"is_holiday\"] == 1) | (df_test[\"is_weekend\"] == 1)).astype(int)\n",
    "\n",
    "    # menu_rank\n",
    "    menu_rank_map = train[['영업장명_메뉴명', 'menu_rank']].drop_duplicates()\n",
    "    df_test = df_test.merge(\n",
    "        menu_rank_map,\n",
    "        on='영업장명_메뉴명',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # 0/1로 정의: non_work = (주말 or 휴일) 이면 1, 평일이면 0\n",
    "    df_test['영업일자'] = pd.to_datetime(df_test['영업일자'])\n",
    "    daily = (df_test.groupby('영업일자', as_index=False)['non_work']\n",
    "                .max()\n",
    "                .sort_values('영업일자'))\n",
    "\n",
    "    # is_sandwich\n",
    "    daily['is_sandwich'] = (\n",
    "        (daily['non_work'].eq(0)) &\n",
    "        (daily['non_work'].shift(1,  fill_value=0).eq(1)) &\n",
    "        (daily['non_work'].shift(-1, fill_value=0).eq(1))\n",
    "    ).astype(int)\n",
    "\n",
    "    # 원본 df_test에 날짜로 merge (기존 컬럼 있으면 덮어쓰기)\n",
    "    df_test = df_test.drop(columns=['is_sandwich'], errors='ignore') \\\n",
    "                    .merge(daily[['영업일자','is_sandwich']], on='영업일자', how='left')\n",
    "    # 0/1로 되어 있다고 가정: non_work = (주말 or 휴일) 1, 평일 0\n",
    "    df_test['영업일자'] = pd.to_datetime(df_test['영업일자'])\n",
    "\n",
    "    # 날짜 단위 non_work(하루에 여러 행이면 max로 대표)\n",
    "    daily = (\n",
    "        df_test.groupby('영업일자', as_index=False)\n",
    "            .agg({\n",
    "                'non_work': 'max',     # 하루에 하나라도 주말/휴일이면 1\n",
    "                'is_holiday': 'max'    # 하루에 하나라도 휴일이면 1\n",
    "            })\n",
    "            .sort_values('영업일자')\n",
    "    )\n",
    "\n",
    "    # 날짜 기준으로 before/after 플래그 계산\n",
    "    daily['is_before_holiday'] = (\n",
    "        (daily['non_work'].eq(0)) &\n",
    "        (daily['non_work'].shift(-1, fill_value=0).eq(1))\n",
    "    ).astype(int)\n",
    "\n",
    "    daily['is_after_holiday'] = (\n",
    "        (daily['non_work'].eq(0)) &\n",
    "        (daily['non_work'].shift(1, fill_value=0).eq(1)) &\n",
    "        (daily['is_holiday'].shift(1, fill_value=0).eq(1))\n",
    "    ).astype(int)\n",
    "    df_test = df_test.merge(\n",
    "        daily[['영업일자', 'is_before_holiday', 'is_after_holiday']],\n",
    "        on='영업일자', how='left'\n",
    "    )\n",
    "    df_test = df_test.drop(columns=['non_work'], errors='ignore')\n",
    "\n",
    "    # 타입/정렬\n",
    "    df_test['영업일자'] = pd.to_datetime(df_test['영업일자'])\n",
    "    df_test = df_test.sort_values(['영업장명','영업일자'])\n",
    "\n",
    "    # lookup features\n",
    "    # menu_category, avg_sales_all_days, avg_sales_nonzero_days, zero_sales_day_ratio, var_sales_nonzero_days, demand_volatility\n",
    "\n",
    "    feat_cols = ['영업장명_메뉴명',\n",
    "             'menu_category','avg_sales_all_days','avg_sales_nonzero_days',\n",
    "             'zero_sales_day_ratio', 'var_sales_nonzero_days', \"demand_volatility\"]\n",
    "    train_feats = (train[feat_cols]\n",
    "               .groupby('영업장명_메뉴명', as_index=False)\n",
    "               .agg('first'))  # 필요시 mean/max로 변경\n",
    "    df_test = df_test.merge(train_feats, on='영업장명_메뉴명',\n",
    "                        how='left', validate='many_to_one')\n",
    "\n",
    "    # menu_date_weight\n",
    "    trainfeats = (\n",
    "        train.groupby(['영업장명_메뉴명', 'month', 'weekday'])['menu_date_weight']\n",
    "            .first()              # 값이 항상 동일하다면 first OK (혹시 다르면 mean 권장)\n",
    "            .reset_index()\n",
    "    )\n",
    "    df_test = df_test.merge(\n",
    "        trainfeats,\n",
    "        on=['영업장명_메뉴명', 'month', 'weekday'],\n",
    "        how='left',\n",
    "        validate='many_to_one'       # test 다대, trainfeats 일대\n",
    "    )\n",
    "\n",
    "    # avg_sales_nonzero_monthly\n",
    "    trainfeats = (\n",
    "        train.groupby(['영업장명_메뉴명', 'month'])['avg_sales_nonzero_monthly']\n",
    "            .first()              # 값이 항상 동일하다면 first OK (혹시 다르면 mean 권장)\n",
    "            .reset_index()\n",
    "    )\n",
    "    df_test = df_test.merge(\n",
    "        trainfeats,\n",
    "        on=['영업장명_메뉴명', 'month'],\n",
    "        how='left',\n",
    "        validate='many_to_one'       # test 다대, trainfeats 일대\n",
    "    )\n",
    "    \n",
    "    # avg_sales_nonzero_seasonly\n",
    "    trainfeats = (\n",
    "        train.groupby(['영업장명_메뉴명', 'season'])['avg_sales_nonzero_seasonly']\n",
    "            .first()              # 값이 항상 동일하다면 first OK (혹시 다르면 mean 권장)\n",
    "            .reset_index()\n",
    "    )\n",
    "    df_test = df_test.merge(\n",
    "        trainfeats,\n",
    "        on=['영업장명_메뉴명', 'season'],\n",
    "        how='left',\n",
    "        validate='many_to_one'       # test 다대, trainfeats 일대\n",
    "    )\n",
    "\n",
    "    # avg_sales_nonzero_weekday\n",
    "    trainfeats = (\n",
    "        train.groupby(['영업장명_메뉴명', 'weekday'])['avg_sales_nonzero_weekday']\n",
    "            .first()              # 값이 항상 동일하다면 first OK (혹시 다르면 mean 권장)\n",
    "            .reset_index()\n",
    "    )\n",
    "    df_test = df_test.merge(\n",
    "        trainfeats,\n",
    "        on=['영업장명_메뉴명', 'weekday'],\n",
    "        how='left',\n",
    "        validate='many_to_one'       # test 다대, trainfeats 일대\n",
    "    )\n",
    "\n",
    "    # weekday_score\n",
    "    trainfeats = (\n",
    "        train.groupby(['영업장명_메뉴명', 'weekday'])['weekday_score']\n",
    "            .first()              # 값이 항상 동일하다면 first OK (혹시 다르면 mean 권장)\n",
    "            .reset_index()\n",
    "    )\n",
    "    df_test = df_test.merge(\n",
    "        trainfeats,\n",
    "        on=['영업장명_메뉴명', 'weekday'],\n",
    "        how='left',\n",
    "        validate='many_to_one'       # test 다대, trainfeats 일대\n",
    "    )\n",
    "\n",
    "    # month_score\n",
    "    trainfeats = (\n",
    "        train.groupby(['영업장명_메뉴명', 'month'])['month_score']\n",
    "            .first()              # 값이 항상 동일하다면 first OK (혹시 다르면 mean 권장)\n",
    "            .reset_index()\n",
    "    )\n",
    "    df_test = df_test.merge(\n",
    "        trainfeats,\n",
    "        on=['영업장명_메뉴명', 'month'],\n",
    "        how='left',\n",
    "        validate='many_to_one'       # test 다대, trainfeats 일대\n",
    "    )\n",
    "\n",
    "    \n",
    "    # date_weight\n",
    "    df_test = df_test.sort_values(['영업장명_메뉴명', '영업일자']).reset_index(drop=True)\n",
    "    df = df_test.copy().sort_values(['영업장명_메뉴명','영업일자']).reset_index(drop=True)\n",
    "    df['is_special'] = ((df['is_holiday']==1) | (df['is_weekend']==1)).astype(int)\n",
    "\n",
    "    def mark_sandwich_adjacent(g: pd.DataFrame) -> pd.DataFrame:\n",
    "        prev_special = g['is_special'].shift(1, fill_value=0)\n",
    "        next_special = g['is_special'].shift(-1, fill_value=0)\n",
    "        g['is_sandwich'] = ((prev_special.eq(1)) & (g['is_special'].eq(0)) & (next_special.eq(1))).astype(int)\n",
    "        g['is_adjacent'] = ((g['is_special'].eq(0)) & (prev_special.eq(1) | next_special.eq(1))).astype(int)\n",
    "        return g\n",
    "\n",
    "    df = df.groupby('영업장명', group_keys=False).apply(mark_sandwich_adjacent)\n",
    "\n",
    "\n",
    "    def build_mask(name: str, g: pd.DataFrame, rule: dict):\n",
    "        \"\"\"name 키워드와 rule 파라미터로 boolean mask 생성\"\"\"\n",
    "        if name == 'holiday':\n",
    "            return g['is_holiday'].eq(1)\n",
    "        if name == 'weekend':\n",
    "            return (g['is_holiday'].eq(0) & g['is_weekend'].eq(1))\n",
    "        if name == 'sandwich':\n",
    "            return (g['is_holiday'].eq(0) & g['is_weekend'].eq(0) & g['is_sandwich'].eq(1))\n",
    "        if name == 'adjacent':\n",
    "            return (g['is_holiday'].eq(0) & g['is_weekend'].eq(0) & g['is_adjacent'].eq(1))\n",
    "        if name == 'friday':\n",
    "            return (g['is_holiday'].eq(0) & g['is_weekend'].eq(0) & g['weekday'].eq(4))\n",
    "        if name == 'tuewedthu':\n",
    "            return (g['is_holiday'].eq(0) & g['is_weekend'].eq(0) & g['weekday'].isin([1,2,3]))\n",
    "        if name == 'monday':\n",
    "            return (g['is_holiday'].eq(0) & g['is_weekend'].eq(0) & g['weekday'].eq(0))\n",
    "        if name == 'weekday_in':\n",
    "            days = rule.get('days', [])\n",
    "            return (g['is_holiday'].eq(0) & g['is_weekend'].eq(0) & g['weekday'].isin(days))\n",
    "        if name == 'custom_mask':\n",
    "            return rule['func'](g)\n",
    "\n",
    "        # ---- 여기부터 추가된 복합 규칙들 ----\n",
    "        # 화~금 (평일만, 휴일/주말 제외)\n",
    "        if name == 'tuewedthufri':\n",
    "            return (g['is_holiday'].eq(0) & g['is_weekend'].eq(0) & g['weekday'].isin([1,2,3,4]))\n",
    "        # 월~목 (평일만, 휴일/주말 제외)\n",
    "        if name == 'montuewedthu':\n",
    "            return (g['is_holiday'].eq(0) & g['is_weekend'].eq(0) & g['weekday'].isin([0,1,2,3]))\n",
    "        # 목/금 (휴일 여부 무관하게 요일만 기준; 위에서 공휴일이 먼저 매칭되므로 충돌 없음)\n",
    "        if name == 'thufri':\n",
    "            return g['weekday'].isin([3,4])\n",
    "        # 화/토 (토요일은 주말이지만, 휴일은 제외하여 공휴일 규칙 우선)\n",
    "        if name == 'tuesat':\n",
    "            return (g['is_holiday'].eq(0) & g['weekday'].isin([1,5]))\n",
    "        # 월/화/수/토/일 (휴일 제외; 연회장/BBQ용)\n",
    "        if name == 'montuewedsatsun':\n",
    "            return (g['is_holiday'].eq(0) & g['weekday'].isin([0,1,2,5,6]))\n",
    "        # 월/일 (휴일 제외)\n",
    "        if name == 'monsun':\n",
    "            return (g['is_holiday'].eq(0) & g['weekday'].isin([0,6]))\n",
    "\n",
    "        raise ValueError(f\"Unknown rule name: {name}\")\n",
    "\n",
    "    def apply_date_rules(g: pd.DataFrame, rules: list, default_val: float=1.0) -> pd.Series:\n",
    "        \"\"\"우선순위대로 date_mult를 채움\"\"\"\n",
    "        out = pd.Series(default_val, index=g.index, dtype=float)\n",
    "        assigned = pd.Series(False, index=g.index)\n",
    "        for r in rules:\n",
    "            name = r['name']\n",
    "            mult = r['mult']\n",
    "            mask = build_mask(name, g, r) & (~assigned)\n",
    "            out.loc[mask] = mult\n",
    "            assigned.loc[mask] = True\n",
    "        return out\n",
    "\n",
    "    def apply_month_rules(g: pd.DataFrame, rules: list, default_val: float=1.0) -> pd.Series:\n",
    "        \"\"\"여러 월/일 조건을 병렬로 적용(후속 규칙이 덮어씀)\"\"\"\n",
    "        out = pd.Series(default_val, index=g.index, dtype=float)\n",
    "        for r in rules:\n",
    "            mult = r['mult']\n",
    "            if 'months' in r:\n",
    "                mask = g['month'].isin(r['months'])\n",
    "            elif 'month' in r and ('day_from' in r or 'day_to' in r):\n",
    "                # 단일 월 + 일자 범위\n",
    "                mask = g['month'].eq(r['month'])\n",
    "                if 'day_from' in r:\n",
    "                    mask &= g['day'] >= r['day_from']\n",
    "                if 'day_to' in r:\n",
    "                    mask &= g['day'] <= r['day_to']\n",
    "            elif 'custom_mask' in r:\n",
    "                mask = r['custom_mask'](g)\n",
    "            else:\n",
    "                continue\n",
    "            out.loc[mask] = mult\n",
    "        return out\n",
    "\n",
    "    CONFIG = {\n",
    "        # 예시) 포레스트릿\n",
    "        '포레스트릿': {\n",
    "            'date': {\n",
    "                'default': 1.0,\n",
    "                'rules': [\n",
    "                    {'name':'holiday',   'mult':1.35},\n",
    "                    {'name':'weekend',   'mult':1.20},\n",
    "                    {'name':'sandwich',  'mult':1.10},\n",
    "                    {'name':'adjacent',  'mult':1.06},\n",
    "                    {'name':'friday',    'mult':1.03},\n",
    "                    {'name':'tuewedthu', 'mult':1.00},\n",
    "                ]\n",
    "            },\n",
    "            'month': {\n",
    "                'default': 1.0,\n",
    "                'rules': [\n",
    "                    {'months':[1,2,12],        'mult':1.20},\n",
    "                    {'months':[4,5,6,9,10,11], 'mult':1.10},\n",
    "                    {'months':[3,7,8],         'mult':0.92},\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        '카페테리아': {\n",
    "            'date': {\n",
    "                'default': 1.0,\n",
    "                'rules': [\n",
    "                    {'name':'holiday',   'mult':1.35},\n",
    "                    {'name':'weekend',   'mult':1.20},\n",
    "                    {'name':'sandwich',  'mult':1.10},\n",
    "                    {'name':'adjacent',  'mult':1.06},\n",
    "                    {'name':'friday',    'mult':1.03},\n",
    "                    {'name':'tuewedthu', 'mult':1.00},\n",
    "                ]\n",
    "            },\n",
    "            'month': {\n",
    "                'default': 1.0,\n",
    "                'rules': [\n",
    "                    {'months':[1,2,12],         'mult':1.20},\n",
    "                    {'months':[9,10],           'mult':1.10},\n",
    "                    {'months':[3,4,5,6,7,8,11], 'mult':0.92},\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        # (예시) 미라시아 — 규칙이 다르다고 가정\n",
    "        '화담숲주막': {\n",
    "            'date': {\n",
    "                'default': 1.0,\n",
    "                'rules': [\n",
    "                    {'name':'holiday',   'mult':1.35},   # 공휴일 더 강하게\n",
    "                    {'name':'weekend',   'mult':1.20},\n",
    "                    {'name':'sandwich',  'mult':1.10},\n",
    "                    {'name':'adjacent',  'mult':1.06},\n",
    "                    {'name':'tuewedthufri', 'mult':1.00},\n",
    "                    {'name':'monday',    'mult':0.97},   # 월요일 약세 반영\n",
    "                ]\n",
    "            },\n",
    "            'month': {\n",
    "                'default': 1.0,\n",
    "                'rules': [\n",
    "                    {'months':[4,5,6,10,11],         'mult':1.20},\n",
    "                    {'months':[7,8,9],           'mult':1.10},\n",
    "                    {'months':[1,2,3,12], 'mult':0.92},\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        '화담숲카페': {\n",
    "            'date': {\n",
    "                'default': 1.0,\n",
    "                'rules': [\n",
    "                    {'name':'holiday',   'mult':1.35},   # 공휴일 더 강하게\n",
    "                    {'name':'weekend',   'mult':1.20},\n",
    "                    {'name':'sandwich',  'mult':1.10},\n",
    "                    {'name':'adjacent',  'mult':1.06},\n",
    "                    {'name':'tuewedthufri', 'mult':1.00},\n",
    "                    {'name':'monday',    'mult':0.97},   # 월요일 약세 반영\n",
    "                ]\n",
    "            },\n",
    "            'month': {\n",
    "                'default': 1.0,\n",
    "                'rules': [\n",
    "                    {'months':[4,5,6,10,11],         'mult':1.20},\n",
    "                    {'months':[7,8,9],           'mult':1.10},\n",
    "                    {'months':[1,2,3,12], 'mult':0.92},\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        '미라시아': {\n",
    "            'date': {\n",
    "                'default': 1.0,\n",
    "                'rules': [\n",
    "                    {'name':'holiday',   'mult':1.35},   # 공휴일 더 강하게\n",
    "                    {'name':'weekend',   'mult':1.20},\n",
    "                    {'name':'sandwich',  'mult':1.10},\n",
    "                    {'name':'adjacent',  'mult':1.06},\n",
    "                    {'name':'friday', 'mult':1.03},\n",
    "                    {'name':'montuewedthu',    'mult':1.00},   # 월요일 약세 반영\n",
    "                ]\n",
    "            },\n",
    "            'month': {\n",
    "                'default': 1.0,\n",
    "                'rules': [\n",
    "                    {'months':[1,2,9,10,11],         'mult':1.20},\n",
    "                    {'months':[8],           'mult':1.10},\n",
    "                    {'months':[4,5,6,7,12], 'mult':1.05},\n",
    "                    {'months':[3], 'mult':0.92},\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        '담하': {\n",
    "            'date': {\n",
    "                'default': 1.0,\n",
    "                'rules': [\n",
    "                    {'name':'holiday',   'mult':1.35},   # 공휴일 더 강하게\n",
    "                    {'name':'weekend',   'mult':1.20},\n",
    "                    {'name':'sandwich',  'mult':1.10},\n",
    "                    {'name':'adjacent',  'mult':1.06},\n",
    "                    {'name':'friday', 'mult':1.03},\n",
    "                    {'name':'montuewedthu',    'mult':1.00},   # 월요일 약세 반영\n",
    "                ]\n",
    "            },\n",
    "            'month': {\n",
    "                'default': 1.0,\n",
    "                'rules': [\n",
    "                    {'months':[1,2,10,11],         'mult':1.20},\n",
    "                    {'months':[4,5,6,7,8,9,12], 'mult':1.10},\n",
    "                    {'months':[3], 'mult':0.92},\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        '라그로타': {\n",
    "            'date': {\n",
    "                'default': 1.0,\n",
    "                'rules': [\n",
    "                    {'name':'holiday',   'mult':1.35},   # 공휴일 더 강하게\n",
    "                    {'name':'weekend',   'mult':1.20},\n",
    "                    {'name':'sandwich',  'mult':1.10},\n",
    "                    {'name':'adjacent',  'mult':1.06},\n",
    "                    {'name':'friday', 'mult':1.03},\n",
    "                    {'name':'tuewedthu',    'mult':1.00},   # 월요일 약세 반영\n",
    "                    {'name':'monday',    'mult':0.97},   # 월요일 약세 반영\n",
    "                ]\n",
    "            },\n",
    "            'month': {\n",
    "                'default': 1.0,\n",
    "                'rules': [\n",
    "                    {'months':[1,2,12],         'mult':1.20},\n",
    "                    {'months':[4,5,6,7,8,9,10,11], 'mult':1.10},\n",
    "                    {'months':[3], 'mult':0.92},\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        '느티나무 셀프BBQ': {\n",
    "            'date': {\n",
    "                'default': 1.0,\n",
    "                'rules': [\n",
    "                    {'name':'thufri',   'mult':1.20},   # 공휴일 더 강하게\n",
    "                    {'name':'montuewedsatsun',   'mult':1.00},\n",
    "                ]\n",
    "            },\n",
    "            'month': {\n",
    "                'default': 1.0,\n",
    "                'rules': [\n",
    "                    {'months':[4,5,6,7,9,10,11,12],         'mult':1.20},\n",
    "                    {'months':[1,2,3,8], 'mult':1.00},\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        '연회장': {\n",
    "            'date': {\n",
    "                'default': 1.0,\n",
    "                'rules': [\n",
    "                    {'name':'thufri',   'mult':1.20},   # 공휴일 더 강하게\n",
    "                    {'name':'tuesat',   'mult':1.10},\n",
    "                    {'name':'monsun',   'mult':1.00},\n",
    "                ]\n",
    "            },\n",
    "            'month': {\n",
    "                'default': 1.0,\n",
    "                'rules': [\n",
    "                    {'months':[1,2,3,4,5,6,7,8,9,10,11,12], 'mult':1.00},\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        \n",
    "    }\n",
    "\n",
    "    \n",
    "    df['date_mult']  = 1.0\n",
    "    df['month_mult'] = 1.0\n",
    "\n",
    "    for store, g in df.groupby('영업장명'):\n",
    "        if store not in CONFIG:\n",
    "            raise KeyError(f\"CONFIG에 '{store}'가 없습니다.\")\n",
    "        conf = CONFIG[store]\n",
    "        date_mult  = apply_date_rules(g, conf['date']['rules'],  conf['date'].get('default', 1.0))\n",
    "        month_mult = apply_month_rules(g, conf['month']['rules'], conf['month'].get('default', 1.0))\n",
    "        df.loc[g.index, 'date_mult']  = date_mult.values\n",
    "        df.loc[g.index, 'month_mult'] = month_mult.values\n",
    "\n",
    "    # 최종 배수 및 안정화\n",
    "    df['date_weight'] = (df['date_mult'] * df['month_mult']).clip(0.7, 1.6)  # 범위는 필요 시 조정\n",
    "\n",
    "    # 결과\n",
    "    df_test['date_weight'] = df['date_weight'].values\n",
    "\n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0baba5",
   "metadata": {},
   "source": [
    "## Process each test file\n",
    "\n",
    "### Subtask:\n",
    "Iterate through the list of test file paths. For each file:\n",
    "    - Load the CSV into a DataFrame.\n",
    "    - Apply the feature engineering function to the DataFrame.\n",
    "    - Store the processed DataFrame (e.g., in a dictionary or list).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8fe5f9",
   "metadata": {},
   "source": [
    "**Reasoning**:\n",
    "Iterate through the test files, apply the feature engineering function to each, and store the results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "id": "ed09f328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/garden/Desktop/lgaimers/Hackaton/DataProcessing/re_data_processed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing TEST_00.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3t/x_vcdczj5fn_v1nnkppzjpwh0000gn/T/ipykernel_10003/2915347979.py:233: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('영업장명', group_keys=False).apply(mark_sandwich_adjacent)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing TEST_00.csv.\n",
      "Processing TEST_01.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3t/x_vcdczj5fn_v1nnkppzjpwh0000gn/T/ipykernel_10003/2915347979.py:233: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('영업장명', group_keys=False).apply(mark_sandwich_adjacent)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing TEST_01.csv.\n",
      "Processing TEST_02.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3t/x_vcdczj5fn_v1nnkppzjpwh0000gn/T/ipykernel_10003/2915347979.py:233: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('영업장명', group_keys=False).apply(mark_sandwich_adjacent)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing TEST_02.csv.\n",
      "Processing TEST_03.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3t/x_vcdczj5fn_v1nnkppzjpwh0000gn/T/ipykernel_10003/2915347979.py:233: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('영업장명', group_keys=False).apply(mark_sandwich_adjacent)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing TEST_03.csv.\n",
      "Processing TEST_04.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3t/x_vcdczj5fn_v1nnkppzjpwh0000gn/T/ipykernel_10003/2915347979.py:233: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('영업장명', group_keys=False).apply(mark_sandwich_adjacent)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing TEST_04.csv.\n",
      "Processing TEST_05.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3t/x_vcdczj5fn_v1nnkppzjpwh0000gn/T/ipykernel_10003/2915347979.py:233: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('영업장명', group_keys=False).apply(mark_sandwich_adjacent)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing TEST_05.csv.\n",
      "Processing TEST_06.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3t/x_vcdczj5fn_v1nnkppzjpwh0000gn/T/ipykernel_10003/2915347979.py:233: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('영업장명', group_keys=False).apply(mark_sandwich_adjacent)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing TEST_06.csv.\n",
      "Processing TEST_07.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3t/x_vcdczj5fn_v1nnkppzjpwh0000gn/T/ipykernel_10003/2915347979.py:233: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('영업장명', group_keys=False).apply(mark_sandwich_adjacent)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing TEST_07.csv.\n",
      "Processing TEST_08.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3t/x_vcdczj5fn_v1nnkppzjpwh0000gn/T/ipykernel_10003/2915347979.py:233: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('영업장명', group_keys=False).apply(mark_sandwich_adjacent)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing TEST_08.csv.\n",
      "Processing TEST_09.csv...\n",
      "Finished processing TEST_09.csv.\n",
      "\n",
      "Sample of processed TEST_00.csv:\n",
      "['영업일자', '영업장명_메뉴명', '매출수량', '영업장명', '메뉴명', 'year', 'month', 'day', 'weekday', 'season', 'quarter', 'solar_term', 'season_sum', 'solar_term_sum', 'quarter_sum', 'is_holiday', 'is_weekend', 'menu_rank', 'is_sandwich', 'is_before_holiday', 'is_after_holiday', 'menu_category', 'avg_sales_all_days', 'avg_sales_nonzero_days', 'zero_sales_day_ratio', 'var_sales_nonzero_days', 'demand_volatility', 'menu_date_weight', 'avg_sales_nonzero_monthly', 'avg_sales_nonzero_seasonly', 'avg_sales_nonzero_weekday', 'weekday_score', 'month_score', 'date_weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3t/x_vcdczj5fn_v1nnkppzjpwh0000gn/T/ipykernel_10003/2915347979.py:233: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('영업장명', group_keys=False).apply(mark_sandwich_adjacent)\n"
     ]
    }
   ],
   "source": [
    "processed_test_dfs = {}\n",
    "\n",
    "# Load necessary dataframes outside the loop\n",
    "print(os.getcwd())  # Ensure the current working directory is set correctly\n",
    "terms_df = pd.read_csv('../solar_term_2023_2025.csv')  # Load the terms CSV\n",
    "holiday_df = pd.read_csv('../holidays_2023_2025.csv')\n",
    "banquet_df_full = pd.read_csv('train_fin.csv') # Load the processed train data\n",
    "\n",
    "# Prepare the banquet_df for merging (only date and type)\n",
    "# banquet_df_for_merge = banquet_df_full[['영업일자', 'banquet_type']].drop_duplicates()\n",
    "\n",
    "for file_path in test_files:\n",
    "    print(f\"Processing {file_path}...\")\n",
    "    # Load the test data\n",
    "    df_test = pd.read_csv(f\"../../data/test/{file_path}\")\n",
    "\n",
    "    # Apply feature engineering\n",
    "    # Pass the necessary dataframes to the function\n",
    "    processed_df = engineer_features(df_test, holiday_df, terms_df)\n",
    "\n",
    "    # Store the processed DataFrame\n",
    "    processed_test_dfs[file_path] = processed_df\n",
    "    print(f\"Finished processing {file_path}.\")\n",
    "\n",
    "# Display the first few rows of one of the processed dataframes to verify\n",
    "if processed_test_dfs:\n",
    "    first_file = list(processed_test_dfs.keys())[0]\n",
    "    print(f\"\\nSample of processed {first_file}:\")\n",
    "    print(processed_test_dfs[first_file].columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefe2568",
   "metadata": {},
   "source": [
    "## Save processed test data (optional)\n",
    "\n",
    "### Subtask:\n",
    "Save each processed test DataFrame to a new CSV file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f97d77",
   "metadata": {},
   "source": [
    "**Reasoning**:\n",
    "Iterate through the processed test dataframes and save each one to a CSV file with an added suffix.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "id": "b23158e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed TEST_00.csv to ./test_processed_fin/TEST_00_processed.csv\n",
      "Saved processed TEST_01.csv to ./test_processed_fin/TEST_01_processed.csv\n",
      "Saved processed TEST_02.csv to ./test_processed_fin/TEST_02_processed.csv\n",
      "Saved processed TEST_03.csv to ./test_processed_fin/TEST_03_processed.csv\n",
      "Saved processed TEST_04.csv to ./test_processed_fin/TEST_04_processed.csv\n",
      "Saved processed TEST_05.csv to ./test_processed_fin/TEST_05_processed.csv\n",
      "Saved processed TEST_06.csv to ./test_processed_fin/TEST_06_processed.csv\n",
      "Saved processed TEST_07.csv to ./test_processed_fin/TEST_07_processed.csv\n",
      "Saved processed TEST_08.csv to ./test_processed_fin/TEST_08_processed.csv\n",
      "Saved processed TEST_09.csv to ./test_processed_fin/TEST_09_processed.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "output_dir = \"./test_processed_fin/\" # Save in the current directory\n",
    "\n",
    "for filename, df_processed in processed_test_dfs.items():\n",
    "    # Construct output filename by adding '_processed' before the extension\n",
    "    base, ext = os.path.splitext(filename)\n",
    "    output_filename = f\"{base}_processed{ext}\"\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "\n",
    "    # Save the DataFrame to CSV\n",
    "    df_processed.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "    \n",
    "\n",
    "    print(f\"Saved processed {filename} to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
